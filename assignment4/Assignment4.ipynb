{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "**Submission deadline: last lab session before or on Wednesday, 22.11.17**\n",
    "\n",
    "**Edit (21.11.17): the problems 7 and 8 are due on Wednesday, 29.11.17. Please submit them via email, and remind the instrictor to grade them during the next lab session**\n",
    "\n",
    "**Points: 11 + 4 bonus points**\n",
    "\n",
    "\n",
    "## Downloading this notebook\n",
    "\n",
    "This assignment is an Jupyter notebook. Download it by cloning https://github.com/janchorowski/nn_assignments. Follow the instructions in its README for instructions.\n",
    "\n",
    "Please do not hesitate to use GitHubâ€™s pull requests to send us corrections!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter code: network for Irises in Pytorch\n",
    "\n",
    "\n",
    "In the following cells a feedforward neural network has been implemented with the aid of PyTorch and its autograd mechanism. Please study the code - many network implementations follow a similar pattern.\n",
    "\n",
    "The provided network trains to nearly 100% accuracy on Iris using Batch Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    \n",
    "    def train_mode(self):\n",
    "        \"\"\"Put layer into training mode.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def eval_mode(self):\n",
    "        \"\"\"Put layer into evalation mode.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        self.W = Variable(torch.FloatTensor(num_in, num_out),\n",
    "                          requires_grad=True)\n",
    "        self.W.name = 'W'\n",
    "        self.b = Variable(torch.FloatTensor(1, num_out),\n",
    "                          requires_grad=True)\n",
    "        self.b.name = 'b'\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.W, self.b]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.mm(self.W) + self.b\n",
    "\n",
    "    \n",
    "class TanhLayer(Layer):\n",
    "    def forward(self, x):\n",
    "        return F.tanh(x)\n",
    "\n",
    "    \n",
    "class  ReLULayer(Layer):\n",
    "    def forward(self, x):\n",
    "        return F.relu(x)\n",
    "\n",
    "\n",
    "class SoftMaxLayer(Layer):\n",
    "    def forward(self, x):\n",
    "        return F.softmax(x)\n",
    "    \n",
    "class DropoutLayer(Layer):\n",
    "    def __init__(self, dropout_p = 0.5):\n",
    "        self.enable = True\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "    def train_mode(self):\n",
    "        #print(\"SWITCH_TRAIN_MODE\")\n",
    "        self.enable = True\n",
    "    \n",
    "    def eval_mode(self):\n",
    "        #print(\"SWITCH_EVAL_MODE\")\n",
    "        self.enable = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.dropout(x, p = self.dropout_p, training = self.enable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeedforwardNet(object):\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.parameters\n",
    "        return params\n",
    "\n",
    "    @parameters.setter\n",
    "    def parameters(self, values):\n",
    "        for ownP, newP in zip(self.parameters, values):\n",
    "            ownP.data = newP.data\n",
    "    \n",
    "    def train_mode(self):\n",
    "        for layer in self.layers:\n",
    "            layer.train_mode()\n",
    "    \n",
    "    def eval_mode(self):\n",
    "        for layer in self.layers:\n",
    "            layer.eval_mode()    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, outputs, targets):\n",
    "        return torch.mean(-torch.log(torch.gather(\n",
    "            outputs, 1, targets.unsqueeze(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import torchvision\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "IrisX = iris.data.astype(np.float32)\n",
    "IrisX = (IrisX - IrisX.mean(axis=0, keepdims=True)) / IrisX.std(axis=0, keepdims=True)\n",
    "IrisY = iris.target\n",
    "\n",
    "def GD(model, x, y, alpha=1e-4, max_iters=1000000, tolerance=1e-6):\n",
    "    \"\"\"Simple batch gradient descent\"\"\"\n",
    "    try:\n",
    "        old_loss = np.inf\n",
    "        x = Variable(torch.from_numpy(x), requires_grad=False)\n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64)), requires_grad=False)\n",
    "        model.train_mode()\n",
    "        for i in xrange(max_iters):\n",
    "            outputs = model.forward(x)\n",
    "            loss = model.loss(outputs, y)\n",
    "\n",
    "            loss.backward()\n",
    "            for p in model.parameters:\n",
    "                p.data -= p.grad.data * alpha\n",
    "                # Zero gradients for the next iteration\n",
    "                p.grad.data.zero_()\n",
    "\n",
    "            loss = loss.data[0]\n",
    "            if old_loss < loss:\n",
    "                print \"Iter: %d, loss increased!\" % (i,)\n",
    "            if (old_loss - loss) < tolerance:\n",
    "                print \"Tolerance level reached. Exiting.\"\n",
    "                break\n",
    "            if i % 1000 == 0:\n",
    "                _, predictions = outputs.data.max(dim=1)\n",
    "                err_rate = 100.0 * (predictions != y.data).sum() / outputs.size(0)\n",
    "                print \"Iteration {0: >6} | loss {1: >5.2f} | err rate  {2: >5.2f}%\" \\\n",
    "                      .format(i, loss, err_rate)\n",
    "            old_loss = loss\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration      0 | loss  1.10 | err rate  91.33%\n",
      "Iteration   1000 | loss  0.05 | err rate   2.00%\n",
      "Iteration   2000 | loss  0.04 | err rate   2.00%\n",
      "Iteration   3000 | loss  0.04 | err rate   1.33%\n",
      "Iteration   4000 | loss  0.04 | err rate   1.33%\n",
      "Iteration   5000 | loss  0.04 | err rate   1.33%\n",
      "Iteration   6000 | loss  0.04 | err rate   1.33%\n",
      "Iteration   7000 | loss  0.04 | err rate   1.33%\n",
      "Iteration   8000 | loss  0.04 | err rate   1.33%\n",
      "Iteration   9000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  10000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  11000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  12000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  13000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  14000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  15000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  16000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  17000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  18000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  19000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  20000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  21000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  22000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  23000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  24000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  25000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  26000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  27000 | loss  0.04 | err rate   1.33%\n",
      "Iteration  28000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  29000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  30000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  31000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  32000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  33000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  34000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  35000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  36000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  37000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  38000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  39000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  40000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  41000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  42000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  43000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  44000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  45000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  46000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  47000 | loss  0.03 | err rate   1.33%\n",
      "Iteration  48000 | loss  0.02 | err rate   1.33%\n",
      "Iteration  49000 | loss  0.02 | err rate   1.33%\n",
      "Iteration  50000 | loss  0.02 | err rate   1.33%\n",
      "Iteration  51000 | loss  0.02 | err rate   1.33%\n",
      "Iteration  52000 | loss  0.02 | err rate   0.67%\n",
      "Iteration  53000 | loss  0.02 | err rate   0.67%\n",
      "Iteration  54000 | loss  0.02 | err rate   0.67%\n",
      "Iteration  55000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  56000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  57000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  58000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  59000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  60000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  61000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  62000 | loss  0.01 | err rate   0.00%\n",
      "Iteration  63000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  64000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  65000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  66000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  67000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  68000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  69000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  70000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  71000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  72000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  73000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  74000 | loss  0.00 | err rate   0.00%\n",
      "Iteration  75000 | loss  0.00 | err rate   0.00%\n",
      "Tolerance level reached. Exiting.\n"
     ]
    }
   ],
   "source": [
    "model = FeedforwardNet(\n",
    "    [AffineLayer(4, 10),\n",
    "     TanhLayer(),\n",
    "     AffineLayer(10, 3),\n",
    "     SoftMaxLayer(),\n",
    "    ])\n",
    "\n",
    "# Initialize parameters\n",
    "for p in model.parameters:\n",
    "    if p.name == 'W':\n",
    "        # p.data.normal_(0, 0.05)\n",
    "        p.data.uniform_(-0.1, 0.1)\n",
    "    elif p.name == 'b':\n",
    "        p.data.zero_()\n",
    "    else:\n",
    "        raise ValueError('Unknown parameter name \"%s\"' % p.name)\n",
    "\n",
    "# Train\n",
    "GD(model, IrisX, IrisY, alpha=1e-1, tolerance=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter code for MNIST and SGD scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def printLog(name):\n",
    "    print(name.ljust(20) + str(datetime.datetime.now()))\n",
    "    \n",
    "batch_size = 128\n",
    "data_path = os.environ.get('PYTORCH_DATA_PATH', '../data')\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "\n",
    "_test = torchvision.datasets.MNIST(\n",
    "    data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "# Load training data, split into train and valid sets\n",
    "_train = torchvision.datasets.MNIST(\n",
    "    data_path, train=True, download=True, transform=transform)\n",
    "_train.train_data = _train.train_data[:50000]\n",
    "_train.train_labels = _train.train_labels[:50000]\n",
    "\n",
    "_valid = torchvision.datasets.MNIST(\n",
    "    data_path, train=True, download=True, transform=transform)\n",
    "_valid.train_data = _valid.train_data[50000:]\n",
    "_valid.train_labels = _valid.train_labels[50000:]\n",
    "\n",
    "mnist_loaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        _train, batch_size=batch_size, shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(\n",
    "        _valid, batch_size=batch_size, shuffle=False),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        _test, batch_size=batch_size, shuffle=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(model, data_loader, cuda=False):\n",
    "    model.eval_mode()\n",
    "    num_errs = 0.0\n",
    "    num_examples = 0\n",
    "    for x, y in data_loader:\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        x = Variable(x.view(x.size(0), -1), volatile=True)\n",
    "        y = Variable(y, volatile=True)\n",
    "        outputs = model.forward(x)\n",
    "        _, predictions = outputs.data.max(dim=1)\n",
    "        num_errs += (predictions != y.data).sum()\n",
    "        num_examples += x.size(0)\n",
    "    return 100.0 * num_errs / num_examples\n",
    "\n",
    "def SGD(model, data_loaders, _alpha=[1e-2, 1e-4], num_epochs=1, patience_expansion=1.5, log_every=100, cuda=False, epsilon=5e-3, decay=0):\n",
    "    if cuda:\n",
    "        for p in model.parameters:\n",
    "            p.data = p.data.cuda()\n",
    "    printLog('sdg start')\n",
    "    #\n",
    "    # TODO: Initialize momentum variables\n",
    "    # Hint: You need one velocity matrix for each parameter\n",
    "    #\n",
    "    # velocities = \n",
    "    #\n",
    "    velocities = [torch.zeros(P.size()) for P in model.parameters]\n",
    "    if cuda:\n",
    "        velocities = [v.cuda() for v in velocities]\n",
    "        \n",
    "    printLog('velocities end')\n",
    "    \n",
    "    iter_ = 0\n",
    "    epoch = 0\n",
    "    best_params = None\n",
    "    best_val_err = np.inf\n",
    "    history = {'train_losses': [], 'train_errs': [], 'val_errs': []}\n",
    "    print('Training the model!')\n",
    "    print('Interrupt at any time to evaluate the best validation model so far.')\n",
    "    try:\n",
    "        while epoch < num_epochs:\n",
    "            model.train_mode()\n",
    "            epoch += 1\n",
    "            for x, y in data_loaders['train']:\n",
    "                if cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                iter_ += 1\n",
    "                x = Variable(x.view(x.size(0), -1), requires_grad=False)\n",
    "                y = Variable(y, requires_grad=False)\n",
    "                \n",
    "                out = model.forward(x)\n",
    "                loss = model.loss(out, y)\n",
    "                loss.backward()\n",
    "                _, predictions = out.data.max(dim=1)\n",
    "                err_rate = 100.0 * (predictions != y.data).sum() / out.size(0)\n",
    "\n",
    "                history['train_losses'].append(loss.data[0])\n",
    "                history['train_errs'].append(err_rate)\n",
    "\n",
    "                for p, v in zip(model.parameters, velocities):\n",
    "                    if p.name == 'W':\n",
    "                        #\n",
    "                        # TODO: Implement weight decay addition to gradients\n",
    "                        # p.grad.data += TODO\n",
    "                        # \n",
    "                        p.grad.data += decay * p.data\n",
    "                    \n",
    "                    #\n",
    "                    # TODO: Update learning rate\n",
    "                    # Hint: Use the iteration counter i\n",
    "                    # alpha = TODO\n",
    "                    #\n",
    "                    alpha = _alpha(iter)\n",
    "                    \n",
    "                    #\n",
    "                    # TODO: Set the momentum constant \n",
    "                    # epsilon = TODO\n",
    "                    #\n",
    "                    #epsilon is set by parameter\n",
    "                        \n",
    "                    #\n",
    "                    # TODO: Implement velocity update in momentum\n",
    "                    # v[...] = TODO\n",
    "                    #\n",
    "                    _v = v\n",
    "                    #v = epsilon * (p.grad.data + v)\n",
    "                    v[...] = v * epsilon - p.grad.data * alpha\n",
    "                    \n",
    "                    #\n",
    "                    # TODO: Set a more sensible learning rule here,\n",
    "                    #       using your learning rate schedule and momentum\n",
    "                    # \n",
    "                    #p.data += -alpha * p.grad.data\n",
    "                    p.data += -alpha * p.grad.data + _v\n",
    "                    \n",
    "                    # Zero gradients for the next iteration\n",
    "                    p.grad.data.zero_()\n",
    "\n",
    "                if iter_ % log_every == 0:\n",
    "                    print \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%\" \\\n",
    "                          .format(iter_, loss.data[0], err_rate)\n",
    "            val_err_rate = compute_error_rate(model, data_loaders['valid'], cuda)\n",
    "            history['val_errs'].append((iter_, val_err_rate))\n",
    "            \n",
    "            if val_err_rate < best_val_err:\n",
    "                # Adjust num of epochs\n",
    "                num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
    "                best_epoch = epoch\n",
    "                best_val_err = val_err_rate\n",
    "                best_params = [p.clone().cpu() for p in model.parameters]\n",
    "            m = \"After epoch {0: >2} | valid err rate: {1: >5.2f}% | doing {2: >3} epochs | dt {3:}\" \\\n",
    "                .format(epoch, val_err_rate, num_epochs, str(datetime.datetime.now()))\n",
    "            print '{0}\\n{1}\\n{0}'.format('-' * len(m), m)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    if best_params is not None:\n",
    "        print \"\\nLoading best params on validation set (epoch %d)\\n\" %(best_epoch)\n",
    "        model.parameters = best_params\n",
    "    plot_history(history)\n",
    "\n",
    "def plot_history(history):\n",
    "    figsize(16, 4)\n",
    "    subplot(1,2,1)\n",
    "    train_loss = np.array(history['train_losses'])\n",
    "    semilogy(np.arange(train_loss.shape[0]), train_loss, label='batch train loss')\n",
    "    legend()\n",
    "        \n",
    "    subplot(1,2,2)\n",
    "    train_errs = np.array(history['train_errs'])\n",
    "    plot(np.arange(train_errs.shape[0]), train_errs, label='batch train error rate')\n",
    "    val_errs = np.array(history['val_errs'])\n",
    "    plot(val_errs[:,0], val_errs[:,1], label='validation error rate', color='r')\n",
    "    ylim(0,20)\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Stochastic Gradient Descent [3p]\n",
    "Implement the following additions to the SGD code provided above:\n",
    "  1. **[1p]** momentum\n",
    "  2. **[1p]** learning rate schedule\n",
    "  3. **[1p]** weight decay, in which we additionally minimize for each weight matrix (but typically not the bias) the sum of its elements squared. One way to implement it is to use function `model.parameters` and select all parameters whose names are \"`W`\" and not \"`b`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Tuning the Network for MNIST [4p]\n",
    "\n",
    "Tune the following network to reach **validation error rate below 1.9%**.\n",
    "This should result in a **test error rate below 2%**. To\n",
    "tune the network you will need to:\n",
    "1. Choose the number of layers (more than 1, less than 5);\n",
    "2. Choose the number of neurons in each layer (more than 100,\n",
    "    less than 5000);\n",
    "3. Pick proper weight initialization;\n",
    "4. Pick proper learning rate schedule (need to decay over time,\n",
    "    good range to check on MNIST is about 1e-2 ... 1e-1 at the beginning and\n",
    "    half of that after 10000 batches);\n",
    "5. Pick a momentum constant (probably a constant one will be OK).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start               2017-12-10 15:07:05.676683\n",
      "sdg start           2017-12-10 15:07:05.774933\n",
      "velocities end      2017-12-10 15:07:05.777119\n",
      "Training the model!\n",
      "Interrupt at any time to evaluate the best validation model so far.\n",
      "Minibatch    100  | loss  0.22 | err rate  6.25%\n",
      "Minibatch    200  | loss  0.17 | err rate  3.12%\n",
      "Minibatch    300  | loss  0.14 | err rate  6.25%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  1 | valid err rate:  3.18% | doing   2 epochs | dt 2017-12-10 15:07:13.435098\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch    400  | loss  0.06 | err rate  1.56%\n",
      "Minibatch    500  | loss  0.13 | err rate  5.47%\n",
      "Minibatch    600  | loss  0.07 | err rate  2.34%\n",
      "Minibatch    700  | loss  0.10 | err rate  3.12%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  2 | valid err rate:  2.83% | doing   4 epochs | dt 2017-12-10 15:07:21.027350\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch    800  | loss  0.05 | err rate  2.34%\n",
      "Minibatch    900  | loss  0.07 | err rate  1.56%\n",
      "Minibatch   1000  | loss  0.06 | err rate  2.34%\n",
      "Minibatch   1100  | loss  0.05 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  3 | valid err rate:  2.51% | doing   5 epochs | dt 2017-12-10 15:07:28.587441\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   1200  | loss  0.03 | err rate  0.00%\n",
      "Minibatch   1300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   1400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   1500  | loss  0.12 | err rate  3.91%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  4 | valid err rate:  2.60% | doing   5 epochs | dt 2017-12-10 15:07:36.125477\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   1600  | loss  0.04 | err rate  1.56%\n",
      "Minibatch   1700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   1800  | loss  0.03 | err rate  0.00%\n",
      "Minibatch   1900  | loss  0.04 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  5 | valid err rate:  2.04% | doing   8 epochs | dt 2017-12-10 15:07:43.176517\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   2000  | loss  0.03 | err rate  0.00%\n",
      "Minibatch   2100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   2200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch   2300  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  6 | valid err rate:  2.59% | doing   8 epochs | dt 2017-12-10 15:07:50.364278\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   2400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   2500  | loss  0.03 | err rate  0.78%\n",
      "Minibatch   2600  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   2700  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  7 | valid err rate:  2.07% | doing   8 epochs | dt 2017-12-10 15:07:57.958541\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   2800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   2900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch   3000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   3100  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  8 | valid err rate:  1.99% | doing  13 epochs | dt 2017-12-10 15:08:05.550609\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   3200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   3300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   3400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   3500  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  9 | valid err rate:  2.10% | doing  13 epochs | dt 2017-12-10 15:08:13.157411\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   3600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   3700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   3800  | loss  0.03 | err rate  0.00%\n",
      "Minibatch   3900  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 10 | valid err rate:  1.90% | doing  16 epochs | dt 2017-12-10 15:08:20.753975\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   4000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   4100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   4200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   4300  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 11 | valid err rate:  2.35% | doing  16 epochs | dt 2017-12-10 15:08:28.351084\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   4400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   4500  | loss  0.03 | err rate  0.78%\n",
      "Minibatch   4600  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 12 | valid err rate:  1.98% | doing  16 epochs | dt 2017-12-10 15:08:35.968806\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   4700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   4800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   4900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch   5000  | loss  0.06 | err rate  3.12%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 13 | valid err rate:  2.02% | doing  16 epochs | dt 2017-12-10 15:08:43.540352\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   5100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   5200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   5300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   5400  | loss  0.04 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 14 | valid err rate:  2.08% | doing  16 epochs | dt 2017-12-10 15:08:51.111796\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   5500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   5600  | loss  0.01 | err rate  0.78%\n",
      "Minibatch   5700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   5800  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 15 | valid err rate:  1.83% | doing  23 epochs | dt 2017-12-10 15:08:58.685949\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   5900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   6000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   6100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch   6200  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 16 | valid err rate:  1.87% | doing  23 epochs | dt 2017-12-10 15:09:06.256925\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   6300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   6400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   6500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   6600  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 17 | valid err rate:  1.99% | doing  23 epochs | dt 2017-12-10 15:09:13.821665\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   6700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   6800  | loss  0.01 | err rate  0.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch   6900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch   7000  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 18 | valid err rate:  1.97% | doing  23 epochs | dt 2017-12-10 15:09:21.389025\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   7100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   7200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch   7300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   7400  | loss  0.05 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 19 | valid err rate:  1.81% | doing  29 epochs | dt 2017-12-10 15:09:28.951800\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   7500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   7600  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   7700  | loss  0.03 | err rate  1.56%\n",
      "Minibatch   7800  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 20 | valid err rate:  1.67% | doing  31 epochs | dt 2017-12-10 15:09:36.483750\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   7900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   8000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   8100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   8200  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 21 | valid err rate:  1.88% | doing  31 epochs | dt 2017-12-10 15:09:44.077155\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   8300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   8400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   8500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   8600  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 22 | valid err rate:  1.89% | doing  31 epochs | dt 2017-12-10 15:09:51.502073\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   8700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   8800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   8900  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 23 | valid err rate:  1.74% | doing  31 epochs | dt 2017-12-10 15:09:59.087069\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   9000  | loss  0.00 | err rate  0.00%\n",
      "Minibatch   9100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   9200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   9300  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 24 | valid err rate:  1.83% | doing  31 epochs | dt 2017-12-10 15:10:06.675543\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   9400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   9500  | loss  0.00 | err rate  0.00%\n",
      "Minibatch   9600  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   9700  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 25 | valid err rate:  1.74% | doing  31 epochs | dt 2017-12-10 15:10:14.266189\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   9800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch   9900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  10000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  10100  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 26 | valid err rate:  1.77% | doing  31 epochs | dt 2017-12-10 15:10:21.848948\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  10200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  10300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  10400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  10500  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 27 | valid err rate:  1.76% | doing  31 epochs | dt 2017-12-10 15:10:29.414093\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  10600  | loss  0.00 | err rate  0.00%\n",
      "Minibatch  10700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  10800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  10900  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 28 | valid err rate:  1.88% | doing  31 epochs | dt 2017-12-10 15:10:36.980506\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  11000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  11100  | loss  0.00 | err rate  0.00%\n",
      "Minibatch  11200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  11300  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 29 | valid err rate:  1.76% | doing  31 epochs | dt 2017-12-10 15:10:44.573789\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  11400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  11500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  11600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  11700  | loss  0.04 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 30 | valid err rate:  1.75% | doing  31 epochs | dt 2017-12-10 15:10:52.166788\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  11800  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  11900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  12000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  12100  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 31 | valid err rate:  1.64% | doing  47 epochs | dt 2017-12-10 15:10:59.756769\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  12200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  12300  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  12400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  12500  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 32 | valid err rate:  1.62% | doing  49 epochs | dt 2017-12-10 15:11:07.333763\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  12600  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  12700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  12800  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  12900  | loss  0.03 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 33 | valid err rate:  1.59% | doing  50 epochs | dt 2017-12-10 15:11:14.893045\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  13000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  13100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  13200  | loss  0.02 | err rate  0.00%\n",
      "\n",
      "Loading best params on validation set (epoch 33)\n",
      "\n",
      "stop                2017-12-10 15:11:20.128727\n",
      "Test error rate: 1.92%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAD8CAYAAAB3qPkTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6442acd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# TODO: Pick a network architecture here.\n",
    "#       The one below is just softmax regression.\n",
    "#\n",
    "\n",
    "printLog('start')\n",
    "      \n",
    "model = FeedforwardNet([\n",
    "       AffineLayer(784,1000),\n",
    "       ReLULayer(),\n",
    "       AffineLayer(1000, 700),\n",
    "       TanhLayer(),\n",
    "       AffineLayer(700, 10),\n",
    "       SoftMaxLayer()\n",
    "       ])\n",
    "\n",
    "# Initialize parameters\n",
    "for p in model.parameters:\n",
    "    if p.name == 'W':\n",
    "        p.data.normal_(0, 0.05)\n",
    "        # p.data.uniform_(-0.1, 0.1)\n",
    "    elif p.name == 'b':\n",
    "        p.data.zero_()\n",
    "    else:\n",
    "        raise ValueError('Unknown parameter name \"%s\"' % p.name)\n",
    "\n",
    "        \n",
    "# On lab computers you can set cuda=True !\n",
    "_alpha = lambda i: 1e-1 if i<=10000 else 5e-2\n",
    "SGD(model, mnist_loaders, _alpha=_alpha, decay=1e-3, epsilon=7e-1, cuda=True)\n",
    "\n",
    "printLog('stop')\n",
    "print \"Test error rate: %.2f%%\" % compute_error_rate(model, mnist_loaders['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Dropout [2p]\n",
    "\n",
    "Implement a **dropout** layer and try to train a\n",
    "network getting below 1.5% test error rates with dropout. The best\n",
    "results with dropout are below 1%!\n",
    "\n",
    "Remember to turn off dropout during testing, using `model.train_mode()` and `model.eval_mode()`!\n",
    "\n",
    "Hint: Use [torch.nn.functional.dropout](http://pytorch.org/docs/master/nn.html#torch.nn.functional.dropout).\n",
    "\n",
    "Details: http://arxiv.org/pdf/1207.0580.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start               2017-12-10 14:37:44.464122\n",
      "sdg start           2017-12-10 14:37:44.590265\n",
      "velocities end      2017-12-10 14:37:44.592133\n",
      "Training the model!\n",
      "Interrupt at any time to evaluate the best validation model so far.\n",
      "Minibatch    100  | loss  0.69 | err rate 18.75%\n",
      "Minibatch    200  | loss  0.57 | err rate 16.41%\n",
      "Minibatch    300  | loss  0.38 | err rate 14.06%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  1 | valid err rate:  6.09% | doing   2 epochs | dt 2017-12-10 14:37:53.938155\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch    400  | loss  0.32 | err rate 11.72%\n",
      "Minibatch    500  | loss  0.34 | err rate  9.38%\n",
      "Minibatch    600  | loss  0.37 | err rate 12.50%\n",
      "Minibatch    700  | loss  0.23 | err rate  9.38%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  2 | valid err rate:  4.56% | doing   4 epochs | dt 2017-12-10 14:38:03.448505\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch    800  | loss  0.36 | err rate 11.72%\n",
      "Minibatch    900  | loss  0.29 | err rate  9.38%\n",
      "Minibatch   1000  | loss  0.32 | err rate 10.16%\n",
      "Minibatch   1100  | loss  0.33 | err rate 10.16%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  3 | valid err rate:  3.65% | doing   5 epochs | dt 2017-12-10 14:38:12.963753\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   1200  | loss  0.24 | err rate  6.25%\n",
      "Minibatch   1300  | loss  0.25 | err rate  8.59%\n",
      "Minibatch   1400  | loss  0.29 | err rate  9.38%\n",
      "Minibatch   1500  | loss  0.22 | err rate  7.81%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  4 | valid err rate:  3.31% | doing   7 epochs | dt 2017-12-10 14:38:22.477740\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   1600  | loss  0.29 | err rate  9.38%\n",
      "Minibatch   1700  | loss  0.20 | err rate  5.47%\n",
      "Minibatch   1800  | loss  0.10 | err rate  2.34%\n",
      "Minibatch   1900  | loss  0.18 | err rate  4.69%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  5 | valid err rate:  3.04% | doing   8 epochs | dt 2017-12-10 14:38:31.993929\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   2000  | loss  0.07 | err rate  2.34%\n",
      "Minibatch   2100  | loss  0.15 | err rate  4.69%\n",
      "Minibatch   2200  | loss  0.20 | err rate  4.69%\n",
      "Minibatch   2300  | loss  0.19 | err rate  6.25%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  6 | valid err rate:  2.84% | doing  10 epochs | dt 2017-12-10 14:38:41.522203\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   2400  | loss  0.15 | err rate  4.69%\n",
      "Minibatch   2500  | loss  0.19 | err rate  4.69%\n",
      "Minibatch   2600  | loss  0.14 | err rate  2.34%\n",
      "Minibatch   2700  | loss  0.15 | err rate  4.69%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  7 | valid err rate:  2.70% | doing  11 epochs | dt 2017-12-10 14:38:50.254410\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   2800  | loss  0.12 | err rate  3.91%\n",
      "Minibatch   2900  | loss  0.11 | err rate  5.47%\n",
      "Minibatch   3000  | loss  0.15 | err rate  7.03%\n",
      "Minibatch   3100  | loss  0.05 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  8 | valid err rate:  2.68% | doing  13 epochs | dt 2017-12-10 14:38:56.817205\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   3200  | loss  0.13 | err rate  4.69%\n",
      "Minibatch   3300  | loss  0.11 | err rate  3.91%\n",
      "Minibatch   3400  | loss  0.11 | err rate  2.34%\n",
      "Minibatch   3500  | loss  0.12 | err rate  3.12%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch  9 | valid err rate:  2.51% | doing  14 epochs | dt 2017-12-10 14:39:03.297506\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   3600  | loss  0.06 | err rate  2.34%\n",
      "Minibatch   3700  | loss  0.10 | err rate  4.69%\n",
      "Minibatch   3800  | loss  0.12 | err rate  5.47%\n",
      "Minibatch   3900  | loss  0.08 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 10 | valid err rate:  2.40% | doing  16 epochs | dt 2017-12-10 14:39:09.751853\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   4000  | loss  0.12 | err rate  2.34%\n",
      "Minibatch   4100  | loss  0.12 | err rate  3.12%\n",
      "Minibatch   4200  | loss  0.14 | err rate  4.69%\n",
      "Minibatch   4300  | loss  0.18 | err rate  5.47%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 11 | valid err rate:  2.37% | doing  17 epochs | dt 2017-12-10 14:39:16.210481\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   4400  | loss  0.15 | err rate  7.03%\n",
      "Minibatch   4500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch   4600  | loss  0.08 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 12 | valid err rate:  2.26% | doing  19 epochs | dt 2017-12-10 14:39:22.628843\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   4700  | loss  0.06 | err rate  2.34%\n",
      "Minibatch   4800  | loss  0.08 | err rate  3.12%\n",
      "Minibatch   4900  | loss  0.07 | err rate  2.34%\n",
      "Minibatch   5000  | loss  0.07 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 13 | valid err rate:  2.18% | doing  20 epochs | dt 2017-12-10 14:39:29.199707\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   5100  | loss  0.03 | err rate  0.78%\n",
      "Minibatch   5200  | loss  0.07 | err rate  3.12%\n",
      "Minibatch   5300  | loss  0.05 | err rate  0.78%\n",
      "Minibatch   5400  | loss  0.04 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 14 | valid err rate:  2.08% | doing  22 epochs | dt 2017-12-10 14:39:35.747006\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   5500  | loss  0.08 | err rate  2.34%\n",
      "Minibatch   5600  | loss  0.10 | err rate  4.69%\n",
      "Minibatch   5700  | loss  0.09 | err rate  2.34%\n",
      "Minibatch   5800  | loss  0.05 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 15 | valid err rate:  2.10% | doing  22 epochs | dt 2017-12-10 14:39:42.243894\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   5900  | loss  0.07 | err rate  2.34%\n",
      "Minibatch   6000  | loss  0.04 | err rate  0.78%\n",
      "Minibatch   6100  | loss  0.13 | err rate  4.69%\n",
      "Minibatch   6200  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 16 | valid err rate:  1.97% | doing  25 epochs | dt 2017-12-10 14:39:48.761558\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   6300  | loss  0.09 | err rate  2.34%\n",
      "Minibatch   6400  | loss  0.08 | err rate  2.34%\n",
      "Minibatch   6500  | loss  0.04 | err rate  1.56%\n",
      "Minibatch   6600  | loss  0.05 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 17 | valid err rate:  1.95% | doing  26 epochs | dt 2017-12-10 14:39:55.281874\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   6700  | loss  0.06 | err rate  2.34%\n",
      "Minibatch   6800  | loss  0.10 | err rate  3.91%\n",
      "Minibatch   6900  | loss  0.07 | err rate  2.34%\n",
      "Minibatch   7000  | loss  0.09 | err rate  3.12%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 18 | valid err rate:  1.98% | doing  26 epochs | dt 2017-12-10 14:40:01.808222\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   7100  | loss  0.07 | err rate  1.56%\n",
      "Minibatch   7200  | loss  0.03 | err rate  1.56%\n",
      "Minibatch   7300  | loss  0.07 | err rate  1.56%\n",
      "Minibatch   7400  | loss  0.06 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 19 | valid err rate:  1.91% | doing  29 epochs | dt 2017-12-10 14:40:08.412619\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   7500  | loss  0.10 | err rate  3.91%\n",
      "Minibatch   7600  | loss  0.04 | err rate  1.56%\n",
      "Minibatch   7700  | loss  0.08 | err rate  2.34%\n",
      "Minibatch   7800  | loss  0.14 | err rate  3.12%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 20 | valid err rate:  1.88% | doing  31 epochs | dt 2017-12-10 14:40:14.987379\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   7900  | loss  0.05 | err rate  2.34%\n",
      "Minibatch   8000  | loss  0.04 | err rate  1.56%\n",
      "Minibatch   8100  | loss  0.04 | err rate  0.00%\n",
      "Minibatch   8200  | loss  0.08 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 21 | valid err rate:  1.87% | doing  32 epochs | dt 2017-12-10 14:40:21.622783\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   8300  | loss  0.04 | err rate  1.56%\n",
      "Minibatch   8400  | loss  0.04 | err rate  1.56%\n",
      "Minibatch   8500  | loss  0.06 | err rate  3.12%\n",
      "Minibatch   8600  | loss  0.07 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 22 | valid err rate:  1.84% | doing  34 epochs | dt 2017-12-10 14:40:28.227312\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   8700  | loss  0.03 | err rate  0.78%\n",
      "Minibatch   8800  | loss  0.04 | err rate  1.56%\n",
      "Minibatch   8900  | loss  0.07 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 23 | valid err rate:  1.84% | doing  34 epochs | dt 2017-12-10 14:40:34.845907\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   9000  | loss  0.10 | err rate  3.91%\n",
      "Minibatch   9100  | loss  0.05 | err rate  1.56%\n",
      "Minibatch   9200  | loss  0.03 | err rate  0.78%\n",
      "Minibatch   9300  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 24 | valid err rate:  1.79% | doing  37 epochs | dt 2017-12-10 14:40:41.449973\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   9400  | loss  0.07 | err rate  2.34%\n",
      "Minibatch   9500  | loss  0.03 | err rate  0.00%\n",
      "Minibatch   9600  | loss  0.06 | err rate  2.34%\n",
      "Minibatch   9700  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 25 | valid err rate:  1.82% | doing  37 epochs | dt 2017-12-10 14:40:48.016635\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch   9800  | loss  0.03 | err rate  0.78%\n",
      "Minibatch   9900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  10000  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  10100  | loss  0.03 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 26 | valid err rate:  1.83% | doing  37 epochs | dt 2017-12-10 14:40:54.627639\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  10200  | loss  0.09 | err rate  3.12%\n",
      "Minibatch  10300  | loss  0.06 | err rate  2.34%\n",
      "Minibatch  10400  | loss  0.06 | err rate  1.56%\n",
      "Minibatch  10500  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 27 | valid err rate:  1.79% | doing  37 epochs | dt 2017-12-10 14:41:01.241546\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  10600  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  10700  | loss  0.06 | err rate  1.56%\n",
      "Minibatch  10800  | loss  0.07 | err rate  2.34%\n",
      "Minibatch  10900  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 28 | valid err rate:  1.71% | doing  43 epochs | dt 2017-12-10 14:41:07.857298\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  11000  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  11100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  11200  | loss  0.07 | err rate  2.34%\n",
      "Minibatch  11300  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 29 | valid err rate:  1.71% | doing  43 epochs | dt 2017-12-10 14:41:14.457522\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  11400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  11500  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  11600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  11700  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 30 | valid err rate:  1.67% | doing  46 epochs | dt 2017-12-10 14:41:21.969851\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  11800  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  11900  | loss  0.04 | err rate  2.34%\n",
      "Minibatch  12000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  12100  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 31 | valid err rate:  1.71% | doing  46 epochs | dt 2017-12-10 14:41:31.385147\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  12200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  12300  | loss  0.05 | err rate  0.78%\n",
      "Minibatch  12400  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  12500  | loss  0.05 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 32 | valid err rate:  1.68% | doing  46 epochs | dt 2017-12-10 14:41:37.927228\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  12600  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  12700  | loss  0.06 | err rate  2.34%\n",
      "Minibatch  12800  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  12900  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 33 | valid err rate:  1.65% | doing  50 epochs | dt 2017-12-10 14:41:44.473641\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  13000  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  13100  | loss  0.04 | err rate  0.00%\n",
      "Minibatch  13200  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 34 | valid err rate:  1.73% | doing  50 epochs | dt 2017-12-10 14:41:51.033774\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  13300  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  13400  | loss  0.04 | err rate  2.34%\n",
      "Minibatch  13500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  13600  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 35 | valid err rate:  1.63% | doing  53 epochs | dt 2017-12-10 14:41:57.603782\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  13700  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  13800  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  13900  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  14000  | loss  0.06 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 36 | valid err rate:  1.69% | doing  53 epochs | dt 2017-12-10 14:42:04.155661\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  14100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  14200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  14300  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  14400  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 37 | valid err rate:  1.65% | doing  53 epochs | dt 2017-12-10 14:42:10.690220\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  14500  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  14600  | loss  0.02 | err rate  1.56%\n",
      "Minibatch  14700  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  14800  | loss  0.11 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 38 | valid err rate:  1.55% | doing  58 epochs | dt 2017-12-10 14:42:17.289472\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  14900  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  15000  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  15100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  15200  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 39 | valid err rate:  1.66% | doing  58 epochs | dt 2017-12-10 14:42:23.885104\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  15300  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  15400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  15500  | loss  0.11 | err rate  4.69%\n",
      "Minibatch  15600  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 40 | valid err rate:  1.65% | doing  58 epochs | dt 2017-12-10 14:42:30.482180\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  15700  | loss  0.06 | err rate  2.34%\n",
      "Minibatch  15800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  15900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  16000  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 41 | valid err rate:  1.72% | doing  58 epochs | dt 2017-12-10 14:42:37.103463\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  16100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  16200  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  16300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  16400  | loss  0.03 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 42 | valid err rate:  1.68% | doing  58 epochs | dt 2017-12-10 14:42:43.631002\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  16500  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  16600  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  16700  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  16800  | loss  0.05 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 43 | valid err rate:  1.58% | doing  58 epochs | dt 2017-12-10 14:42:50.237230\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  16900  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  17000  | loss  0.03 | err rate  2.34%\n",
      "Minibatch  17100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  17200  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 44 | valid err rate:  1.64% | doing  58 epochs | dt 2017-12-10 14:42:56.831817\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  17300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  17400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  17500  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 45 | valid err rate:  1.60% | doing  58 epochs | dt 2017-12-10 14:43:03.418529\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  17600  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  17700  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  17800  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  17900  | loss  0.04 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 46 | valid err rate:  1.65% | doing  58 epochs | dt 2017-12-10 14:43:10.024494\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  18000  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  18100  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  18200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  18300  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 47 | valid err rate:  1.59% | doing  58 epochs | dt 2017-12-10 14:43:16.592464\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  18400  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  18500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  18600  | loss  0.06 | err rate  2.34%\n",
      "Minibatch  18700  | loss  0.03 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 48 | valid err rate:  1.61% | doing  58 epochs | dt 2017-12-10 14:43:23.141687\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  18800  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  18900  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  19000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  19100  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 49 | valid err rate:  1.52% | doing  74 epochs | dt 2017-12-10 14:43:29.737363\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  19200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  19300  | loss  0.05 | err rate  3.12%\n",
      "Minibatch  19400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  19500  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 50 | valid err rate:  1.61% | doing  74 epochs | dt 2017-12-10 14:43:36.321965\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  19600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  19700  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  19800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  19900  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 51 | valid err rate:  1.59% | doing  74 epochs | dt 2017-12-10 14:43:42.926818\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  20000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  20100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  20200  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  20300  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 52 | valid err rate:  1.57% | doing  74 epochs | dt 2017-12-10 14:43:49.518805\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  20400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  20500  | loss  0.05 | err rate  2.34%\n",
      "Minibatch  20600  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  20700  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 53 | valid err rate:  1.62% | doing  74 epochs | dt 2017-12-10 14:43:56.122809\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  20800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  20900  | loss  0.05 | err rate  0.78%\n",
      "Minibatch  21000  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  21100  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 54 | valid err rate:  1.60% | doing  74 epochs | dt 2017-12-10 14:44:02.781565\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  21200  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  21300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  21400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  21500  | loss  0.04 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 55 | valid err rate:  1.56% | doing  74 epochs | dt 2017-12-10 14:44:09.416737\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  21600  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  21700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  21800  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 56 | valid err rate:  1.60% | doing  74 epochs | dt 2017-12-10 14:44:16.051351\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  21900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  22000  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  22100  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  22200  | loss  0.03 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 57 | valid err rate:  1.55% | doing  74 epochs | dt 2017-12-10 14:44:22.671810\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  22300  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  22400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  22500  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  22600  | loss  0.03 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 58 | valid err rate:  1.43% | doing  88 epochs | dt 2017-12-10 14:44:29.284472\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  22700  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  22800  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  22900  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  23000  | loss  0.03 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 59 | valid err rate:  1.57% | doing  88 epochs | dt 2017-12-10 14:44:35.949234\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  23100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  23200  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  23300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  23400  | loss  0.06 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 60 | valid err rate:  1.57% | doing  88 epochs | dt 2017-12-10 14:44:42.621869\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  23500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  23600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  23700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  23800  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 61 | valid err rate:  1.53% | doing  88 epochs | dt 2017-12-10 14:44:49.261967\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  23900  | loss  0.02 | err rate  1.56%\n",
      "Minibatch  24000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  24100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  24200  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 62 | valid err rate:  1.48% | doing  88 epochs | dt 2017-12-10 14:44:55.884939\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  24300  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  24400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  24500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  24600  | loss  0.05 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 63 | valid err rate:  1.59% | doing  88 epochs | dt 2017-12-10 14:45:02.564831\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  24700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  24800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  24900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  25000  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 64 | valid err rate:  1.50% | doing  88 epochs | dt 2017-12-10 14:45:09.282156\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  25100  | loss  0.04 | err rate  2.34%\n",
      "Minibatch  25200  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  25300  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  25400  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 65 | valid err rate:  1.60% | doing  88 epochs | dt 2017-12-10 14:45:16.025041\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  25500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  25600  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  25700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  25800  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 66 | valid err rate:  1.58% | doing  88 epochs | dt 2017-12-10 14:45:22.571812\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  25900  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  26000  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  26100  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 67 | valid err rate:  1.43% | doing  88 epochs | dt 2017-12-10 14:45:29.119151\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  26200  | loss  0.06 | err rate  1.56%\n",
      "Minibatch  26300  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  26400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  26500  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 68 | valid err rate:  1.61% | doing  88 epochs | dt 2017-12-10 14:45:35.537004\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  26600  | loss  0.04 | err rate  2.34%\n",
      "Minibatch  26700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  26800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  26900  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 69 | valid err rate:  1.44% | doing  88 epochs | dt 2017-12-10 14:45:41.907088\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  27000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  27100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  27200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  27300  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 70 | valid err rate:  1.56% | doing  88 epochs | dt 2017-12-10 14:45:48.494770\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  27400  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  27500  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  27600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  27700  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 71 | valid err rate:  1.54% | doing  88 epochs | dt 2017-12-10 14:45:54.844048\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  27800  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  27900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  28000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  28100  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 72 | valid err rate:  1.57% | doing  88 epochs | dt 2017-12-10 14:46:01.321358\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  28200  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  28300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  28400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  28500  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 73 | valid err rate:  1.55% | doing  88 epochs | dt 2017-12-10 14:46:10.940505\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  28600  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  28700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  28800  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  28900  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 74 | valid err rate:  1.54% | doing  88 epochs | dt 2017-12-10 14:46:20.912092\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  29000  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  29100  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  29200  | loss  0.06 | err rate  0.78%\n",
      "Minibatch  29300  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 75 | valid err rate:  1.52% | doing  88 epochs | dt 2017-12-10 14:46:30.890358\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  29400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  29500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  29600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  29700  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 76 | valid err rate:  1.55% | doing  88 epochs | dt 2017-12-10 14:46:40.932041\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  29800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  29900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  30000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  30100  | loss  0.05 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 77 | valid err rate:  1.48% | doing  88 epochs | dt 2017-12-10 14:46:51.111152\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  30200  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  30300  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  30400  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 78 | valid err rate:  1.58% | doing  88 epochs | dt 2017-12-10 14:47:00.546907\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  30500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  30600  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  30700  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  30800  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 79 | valid err rate:  1.53% | doing  88 epochs | dt 2017-12-10 14:47:10.680234\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  30900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  31000  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  31100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  31200  | loss  0.04 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 80 | valid err rate:  1.54% | doing  88 epochs | dt 2017-12-10 14:47:20.901792\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  31300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  31400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  31500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  31600  | loss  0.04 | err rate  2.34%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 81 | valid err rate:  1.43% | doing  88 epochs | dt 2017-12-10 14:47:31.103189\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  31700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  31800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  31900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  32000  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 82 | valid err rate:  1.42% | doing 124 epochs | dt 2017-12-10 14:47:41.328572\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  32100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  32200  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  32300  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  32400  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 83 | valid err rate:  1.51% | doing 124 epochs | dt 2017-12-10 14:47:51.552724\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  32500  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  32600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  32700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  32800  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 84 | valid err rate:  1.55% | doing 124 epochs | dt 2017-12-10 14:48:01.787792\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  32900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  33000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  33100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  33200  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 85 | valid err rate:  1.47% | doing 124 epochs | dt 2017-12-10 14:48:12.025983\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  33300  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  33400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  33500  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  33600  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 86 | valid err rate:  1.55% | doing 124 epochs | dt 2017-12-10 14:48:22.233143\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  33700  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  33800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  33900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  34000  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 87 | valid err rate:  1.50% | doing 124 epochs | dt 2017-12-10 14:48:32.467947\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  34100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  34200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  34300  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  34400  | loss  0.06 | err rate  1.56%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 88 | valid err rate:  1.44% | doing 124 epochs | dt 2017-12-10 14:48:42.705153\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  34500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  34600  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  34700  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 89 | valid err rate:  1.51% | doing 124 epochs | dt 2017-12-10 14:48:52.929032\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  34800  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  34900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  35000  | loss  0.05 | err rate  0.78%\n",
      "Minibatch  35100  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 90 | valid err rate:  1.45% | doing 124 epochs | dt 2017-12-10 14:49:03.103528\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  35200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  35300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  35400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  35500  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 91 | valid err rate:  1.48% | doing 124 epochs | dt 2017-12-10 14:49:13.335913\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  35600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  35700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  35800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  35900  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 92 | valid err rate:  1.56% | doing 124 epochs | dt 2017-12-10 14:49:23.557849\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  36000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  36100  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  36200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  36300  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 93 | valid err rate:  1.46% | doing 124 epochs | dt 2017-12-10 14:49:33.777542\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  36400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  36500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  36600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  36700  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 94 | valid err rate:  1.43% | doing 124 epochs | dt 2017-12-10 14:49:43.999922\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  36800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  36900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  37000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  37100  | loss  0.01 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 95 | valid err rate:  1.42% | doing 124 epochs | dt 2017-12-10 14:49:54.232764\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  37200  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  37300  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  37400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  37500  | loss  0.03 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 96 | valid err rate:  1.44% | doing 124 epochs | dt 2017-12-10 14:50:04.466012\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  37600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  37700  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  37800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  37900  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 97 | valid err rate:  1.48% | doing 124 epochs | dt 2017-12-10 14:50:14.698726\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  38000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  38100  | loss  0.03 | err rate  2.34%\n",
      "Minibatch  38200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  38300  | loss  0.02 | err rate  0.78%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 98 | valid err rate:  1.50% | doing 124 epochs | dt 2017-12-10 14:50:24.966555\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  38400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  38500  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  38600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  38700  | loss  0.02 | err rate  0.00%\n",
      "------------------------------------------------------------------------------------------\n",
      "After epoch 99 | valid err rate:  1.50% | doing 124 epochs | dt 2017-12-10 14:50:35.261387\n",
      "------------------------------------------------------------------------------------------\n",
      "Minibatch  38800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  38900  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  39000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  39100  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 100 | valid err rate:  1.47% | doing 124 epochs | dt 2017-12-10 14:50:44.906414\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  39200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  39300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  39400  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 101 | valid err rate:  1.41% | doing 152 epochs | dt 2017-12-10 14:50:51.509448\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  39500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  39600  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  39700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  39800  | loss  0.03 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 102 | valid err rate:  1.48% | doing 152 epochs | dt 2017-12-10 14:50:58.102896\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  39900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  40000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  40100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  40200  | loss  0.03 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 103 | valid err rate:  1.40% | doing 155 epochs | dt 2017-12-10 14:51:04.474300\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  40300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  40400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  40500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  40600  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 104 | valid err rate:  1.46% | doing 155 epochs | dt 2017-12-10 14:51:10.969498\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  40700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  40800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  40900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  41000  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 105 | valid err rate:  1.46% | doing 155 epochs | dt 2017-12-10 14:51:17.380681\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  41100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  41200  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  41300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  41400  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 106 | valid err rate:  1.38% | doing 160 epochs | dt 2017-12-10 14:51:23.701927\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  41500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  41600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  41700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  41800  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 107 | valid err rate:  1.53% | doing 160 epochs | dt 2017-12-10 14:51:30.037723\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  41900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  42000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  42100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  42200  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 108 | valid err rate:  1.41% | doing 160 epochs | dt 2017-12-10 14:51:37.512087\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  42300  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  42400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  42500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  42600  | loss  0.04 | err rate  1.56%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 109 | valid err rate:  1.42% | doing 160 epochs | dt 2017-12-10 14:51:47.585313\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  42700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  42800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  42900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  43000  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 110 | valid err rate:  1.42% | doing 160 epochs | dt 2017-12-10 14:51:57.585688\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  43100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  43200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  43300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  43400  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 111 | valid err rate:  1.45% | doing 160 epochs | dt 2017-12-10 14:52:07.600350\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  43500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  43600  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  43700  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 112 | valid err rate:  1.41% | doing 160 epochs | dt 2017-12-10 14:52:17.623681\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  43800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  43900  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  44000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  44100  | loss  0.03 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 113 | valid err rate:  1.43% | doing 160 epochs | dt 2017-12-10 14:52:27.750008\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  44200  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  44300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  44400  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  44500  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 114 | valid err rate:  1.47% | doing 160 epochs | dt 2017-12-10 14:52:37.983859\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  44600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  44700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  44800  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  44900  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 115 | valid err rate:  1.51% | doing 160 epochs | dt 2017-12-10 14:52:46.112153\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  45000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  45100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  45200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  45300  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 116 | valid err rate:  1.46% | doing 160 epochs | dt 2017-12-10 14:52:52.618399\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  45400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  45500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  45600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  45700  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 117 | valid err rate:  1.46% | doing 160 epochs | dt 2017-12-10 14:52:59.169310\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  45800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  45900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  46000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  46100  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 118 | valid err rate:  1.43% | doing 160 epochs | dt 2017-12-10 14:53:05.981649\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  46200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  46300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  46400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  46500  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 119 | valid err rate:  1.42% | doing 160 epochs | dt 2017-12-10 14:53:12.773303\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  46600  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  46700  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  46800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  46900  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 120 | valid err rate:  1.42% | doing 160 epochs | dt 2017-12-10 14:53:19.609414\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  47000  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  47100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  47200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  47300  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 121 | valid err rate:  1.48% | doing 160 epochs | dt 2017-12-10 14:53:26.443974\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  47400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  47500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  47600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  47700  | loss  0.03 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 122 | valid err rate:  1.41% | doing 160 epochs | dt 2017-12-10 14:53:33.093680\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  47800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  47900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  48000  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 123 | valid err rate:  1.41% | doing 160 epochs | dt 2017-12-10 14:53:39.618647\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  48100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  48200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  48300  | loss  0.02 | err rate  1.56%\n",
      "Minibatch  48400  | loss  0.03 | err rate  1.56%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 124 | valid err rate:  1.44% | doing 160 epochs | dt 2017-12-10 14:53:46.246235\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  48500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  48600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  48700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  48800  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 125 | valid err rate:  1.47% | doing 160 epochs | dt 2017-12-10 14:53:52.766079\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  48900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  49000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  49100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  49200  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 126 | valid err rate:  1.36% | doing 190 epochs | dt 2017-12-10 14:53:59.139481\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  49300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  49400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  49500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  49600  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 127 | valid err rate:  1.47% | doing 190 epochs | dt 2017-12-10 14:54:05.536481\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  49700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  49800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  49900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  50000  | loss  0.03 | err rate  1.56%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 128 | valid err rate:  1.53% | doing 190 epochs | dt 2017-12-10 14:54:11.897632\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  50100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  50200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  50300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  50400  | loss  0.03 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 129 | valid err rate:  1.47% | doing 190 epochs | dt 2017-12-10 14:54:18.292336\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  50500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  50600  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  50700  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  50800  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 130 | valid err rate:  1.42% | doing 190 epochs | dt 2017-12-10 14:54:24.670505\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  50900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  51000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  51100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  51200  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 131 | valid err rate:  1.32% | doing 197 epochs | dt 2017-12-10 14:54:31.023776\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  51300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  51400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  51500  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  51600  | loss  0.03 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 132 | valid err rate:  1.34% | doing 197 epochs | dt 2017-12-10 14:54:37.394157\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  51700  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  51800  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  51900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  52000  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 133 | valid err rate:  1.50% | doing 197 epochs | dt 2017-12-10 14:54:43.752707\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  52100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  52200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  52300  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 134 | valid err rate:  1.43% | doing 197 epochs | dt 2017-12-10 14:54:52.012442\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  52400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  52500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  52600  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  52700  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 135 | valid err rate:  1.45% | doing 197 epochs | dt 2017-12-10 14:55:02.011452\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  52800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  52900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  53000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  53100  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 136 | valid err rate:  1.47% | doing 197 epochs | dt 2017-12-10 14:55:12.092678\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  53200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  53300  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  53400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  53500  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 137 | valid err rate:  1.42% | doing 197 epochs | dt 2017-12-10 14:55:20.668928\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  53600  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  53700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  53800  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  53900  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 138 | valid err rate:  1.44% | doing 197 epochs | dt 2017-12-10 14:55:27.011523\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  54000  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  54100  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  54200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  54300  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 139 | valid err rate:  1.43% | doing 197 epochs | dt 2017-12-10 14:55:33.346922\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  54400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  54500  | loss  0.03 | err rate  1.56%\n",
      "Minibatch  54600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  54700  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 140 | valid err rate:  1.36% | doing 197 epochs | dt 2017-12-10 14:55:39.870787\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  54800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  54900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  55000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  55100  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 141 | valid err rate:  1.42% | doing 197 epochs | dt 2017-12-10 14:55:46.389439\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  55200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  55300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  55400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  55500  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 142 | valid err rate:  1.49% | doing 197 epochs | dt 2017-12-10 14:55:52.942934\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  55600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  55700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  55800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  55900  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 143 | valid err rate:  1.51% | doing 197 epochs | dt 2017-12-10 14:55:59.531700\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  56000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  56100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  56200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  56300  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 144 | valid err rate:  1.54% | doing 197 epochs | dt 2017-12-10 14:56:06.087783\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  56400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  56500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  56600  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 145 | valid err rate:  1.48% | doing 197 epochs | dt 2017-12-10 14:56:12.719136\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  56700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  56800  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  56900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  57000  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 146 | valid err rate:  1.46% | doing 197 epochs | dt 2017-12-10 14:56:19.139594\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  57100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  57200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  57300  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  57400  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 147 | valid err rate:  1.54% | doing 197 epochs | dt 2017-12-10 14:56:25.785040\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  57500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  57600  | loss  0.03 | err rate  0.00%\n",
      "Minibatch  57700  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  57800  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 148 | valid err rate:  1.47% | doing 197 epochs | dt 2017-12-10 14:56:32.457935\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  57900  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  58000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  58100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  58200  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 149 | valid err rate:  1.48% | doing 197 epochs | dt 2017-12-10 14:56:39.217861\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  58300  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  58400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  58500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  58600  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 150 | valid err rate:  1.41% | doing 197 epochs | dt 2017-12-10 14:56:46.084884\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  58700  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  58800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  58900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  59000  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 151 | valid err rate:  1.37% | doing 197 epochs | dt 2017-12-10 14:56:52.960575\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  59100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  59200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  59300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  59400  | loss  0.05 | err rate  1.56%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 152 | valid err rate:  1.48% | doing 197 epochs | dt 2017-12-10 14:56:59.784056\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  59500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  59600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  59700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  59800  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 153 | valid err rate:  1.44% | doing 197 epochs | dt 2017-12-10 14:57:06.433299\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  59900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  60000  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  60100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  60200  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 154 | valid err rate:  1.46% | doing 197 epochs | dt 2017-12-10 14:57:16.035924\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  60300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  60400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  60500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  60600  | loss  0.03 | err rate  1.56%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 155 | valid err rate:  1.38% | doing 197 epochs | dt 2017-12-10 14:57:26.160935\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  60700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  60800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  60900  | loss  0.05 | err rate  2.34%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 156 | valid err rate:  1.43% | doing 197 epochs | dt 2017-12-10 14:57:36.278043\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  61000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  61100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  61200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  61300  | loss  0.04 | err rate  2.34%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 157 | valid err rate:  1.34% | doing 197 epochs | dt 2017-12-10 14:57:46.404112\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  61400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  61500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  61600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  61700  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 158 | valid err rate:  1.38% | doing 197 epochs | dt 2017-12-10 14:57:56.426978\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  61800  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  61900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  62000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  62100  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 159 | valid err rate:  1.40% | doing 197 epochs | dt 2017-12-10 14:58:06.508771\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  62200  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  62300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  62400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  62500  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 160 | valid err rate:  1.32% | doing 197 epochs | dt 2017-12-10 14:58:16.598912\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  62600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  62700  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  62800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  62900  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 161 | valid err rate:  1.46% | doing 197 epochs | dt 2017-12-10 14:58:25.865598\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  63000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  63100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  63200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  63300  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 162 | valid err rate:  1.40% | doing 197 epochs | dt 2017-12-10 14:58:32.431527\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  63400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  63500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  63600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  63700  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 163 | valid err rate:  1.42% | doing 197 epochs | dt 2017-12-10 14:58:38.933306\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  63800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  63900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  64000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  64100  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 164 | valid err rate:  1.43% | doing 197 epochs | dt 2017-12-10 14:58:45.508091\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  64200  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  64300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  64400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  64500  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 165 | valid err rate:  1.44% | doing 197 epochs | dt 2017-12-10 14:58:52.097580\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  64600  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  64700  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  64800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  64900  | loss  0.03 | err rate  1.56%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 166 | valid err rate:  1.40% | doing 197 epochs | dt 2017-12-10 14:58:58.577469\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  65000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  65100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  65200  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 167 | valid err rate:  1.36% | doing 197 epochs | dt 2017-12-10 14:59:04.902791\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  65300  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  65400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  65500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  65600  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 168 | valid err rate:  1.36% | doing 197 epochs | dt 2017-12-10 14:59:11.239990\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  65700  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  65800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  65900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  66000  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 169 | valid err rate:  1.37% | doing 197 epochs | dt 2017-12-10 14:59:17.585414\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  66100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  66200  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  66300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  66400  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 170 | valid err rate:  1.51% | doing 197 epochs | dt 2017-12-10 14:59:23.935854\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  66500  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  66600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  66700  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  66800  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 171 | valid err rate:  1.42% | doing 197 epochs | dt 2017-12-10 14:59:30.499599\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  66900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  67000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  67100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  67200  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 172 | valid err rate:  1.38% | doing 197 epochs | dt 2017-12-10 14:59:37.081296\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  67300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  67400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  67500  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  67600  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 173 | valid err rate:  1.36% | doing 197 epochs | dt 2017-12-10 14:59:43.685910\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  67700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  67800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  67900  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  68000  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 174 | valid err rate:  1.38% | doing 197 epochs | dt 2017-12-10 14:59:50.266451\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  68100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  68200  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  68300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  68400  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 175 | valid err rate:  1.39% | doing 197 epochs | dt 2017-12-10 14:59:56.718119\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  68500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  68600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  68700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  68800  | loss  0.04 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 176 | valid err rate:  1.44% | doing 197 epochs | dt 2017-12-10 15:00:03.024258\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  68900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  69000  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  69100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  69200  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 177 | valid err rate:  1.45% | doing 197 epochs | dt 2017-12-10 15:00:09.519587\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  69300  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  69400  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  69500  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 178 | valid err rate:  1.43% | doing 197 epochs | dt 2017-12-10 15:00:16.095529\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  69600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  69700  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  69800  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  69900  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 179 | valid err rate:  1.37% | doing 197 epochs | dt 2017-12-10 15:00:22.663347\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  70000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  70100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  70200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  70300  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 180 | valid err rate:  1.34% | doing 197 epochs | dt 2017-12-10 15:00:29.244066\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  70400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  70500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  70600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  70700  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 181 | valid err rate:  1.39% | doing 197 epochs | dt 2017-12-10 15:00:35.869803\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  70800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  70900  | loss  0.04 | err rate  0.78%\n",
      "Minibatch  71000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  71100  | loss  0.02 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 182 | valid err rate:  1.35% | doing 197 epochs | dt 2017-12-10 15:00:42.474245\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  71200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  71300  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  71400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  71500  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 183 | valid err rate:  1.40% | doing 197 epochs | dt 2017-12-10 15:00:49.047858\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  71600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  71700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  71800  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  71900  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 184 | valid err rate:  1.34% | doing 197 epochs | dt 2017-12-10 15:00:55.506712\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  72000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  72100  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  72200  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  72300  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 185 | valid err rate:  1.41% | doing 197 epochs | dt 2017-12-10 15:01:01.865815\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  72400  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  72500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  72600  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  72700  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 186 | valid err rate:  1.34% | doing 197 epochs | dt 2017-12-10 15:01:08.193875\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  72800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  72900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  73000  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  73100  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 187 | valid err rate:  1.32% | doing 197 epochs | dt 2017-12-10 15:01:14.744612\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  73200  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  73300  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  73400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  73500  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 188 | valid err rate:  1.35% | doing 197 epochs | dt 2017-12-10 15:01:21.358196\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  73600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  73700  | loss  0.01 | err rate  0.78%\n",
      "Minibatch  73800  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 189 | valid err rate:  1.42% | doing 197 epochs | dt 2017-12-10 15:01:27.943540\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  73900  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  74000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  74100  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  74200  | loss  0.03 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 190 | valid err rate:  1.37% | doing 197 epochs | dt 2017-12-10 15:01:34.520513\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  74300  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  74400  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  74500  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  74600  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 191 | valid err rate:  1.41% | doing 197 epochs | dt 2017-12-10 15:01:41.116806\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  74700  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  74800  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  74900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  75000  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 192 | valid err rate:  1.35% | doing 197 epochs | dt 2017-12-10 15:01:47.504764\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  75100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  75200  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  75300  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  75400  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 193 | valid err rate:  1.32% | doing 197 epochs | dt 2017-12-10 15:01:53.852169\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  75500  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  75600  | loss  0.01 | err rate  0.00%\n",
      "Minibatch  75700  | loss  0.05 | err rate  1.56%\n",
      "Minibatch  75800  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 194 | valid err rate:  1.36% | doing 197 epochs | dt 2017-12-10 15:02:00.264602\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  75900  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  76000  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  76100  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  76200  | loss  0.03 | err rate  0.78%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 195 | valid err rate:  1.43% | doing 197 epochs | dt 2017-12-10 15:02:06.851430\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  76300  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  76400  | loss  0.03 | err rate  0.78%\n",
      "Minibatch  76500  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  76600  | loss  0.01 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 196 | valid err rate:  1.36% | doing 197 epochs | dt 2017-12-10 15:02:13.454253\n",
      "-------------------------------------------------------------------------------------------\n",
      "Minibatch  76700  | loss  0.02 | err rate  0.78%\n",
      "Minibatch  76800  | loss  0.04 | err rate  1.56%\n",
      "Minibatch  76900  | loss  0.02 | err rate  0.00%\n",
      "Minibatch  77000  | loss  0.02 | err rate  0.00%\n",
      "-------------------------------------------------------------------------------------------\n",
      "After epoch 197 | valid err rate:  1.40% | doing 197 epochs | dt 2017-12-10 15:02:20.633058\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Loading best params on validation set (epoch 131)\n",
      "\n",
      "stop                2017-12-10 15:02:20.837296\n",
      "Test error rate: 1.37%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAD8CAYAAABD0TgPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f346868e6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printLog('start')\n",
    "      \n",
    "model = FeedforwardNet([\n",
    "       DropoutLayer(dropout_p = 0.1),\n",
    "       AffineLayer(784,1000),\n",
    "       ReLULayer(),\n",
    "       DropoutLayer(dropout_p = 0.3),\n",
    "       AffineLayer(1000, 700),\n",
    "       TanhLayer(),\n",
    "       DropoutLayer(dropout_p = 0.5),\n",
    "       AffineLayer(700, 10),\n",
    "       SoftMaxLayer()\n",
    "       ])\n",
    "\n",
    "# Initialize parameters\n",
    "for p in model.parameters:\n",
    "    if p.name == 'W':\n",
    "        p.data.normal_(0, 0.05)\n",
    "        # p.data.uniform_(-0.1, 0.1)\n",
    "    elif p.name == 'b':\n",
    "        p.data.zero_()\n",
    "    else:\n",
    "        raise ValueError('Unknown parameter name \"%s\"' % p.name)\n",
    "\n",
    "        \n",
    "# On lab computers you can set cuda=True !\n",
    "_alpha = lambda i: 2e-2 if i<=10000 else 1e-2\n",
    "SGD(model, mnist_loaders, _alpha=_alpha, decay=1e-3, epsilon=0.70, cuda=True)\n",
    "\n",
    "printLog('stop')\n",
    "print \"Test error rate: %.2f%%\" % compute_error_rate(model, mnist_loaders['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Data Augmentation [1p]\n",
    "\n",
    "Apply data augmentation methods (e.g. rotations, noise, crops) when training networks on MNIST, to significantly reduce test error rate for your network. You can use functions from the [torchvision.transforms](http://pytorch.org/docs/master/torchvision/transforms.html) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5: Batch Normalization [1p]\n",
    "\n",
    "*Covariate shift* is a phenomenon associated with training deep models. Simply put, weight changes in early layers cause major changes in distribution of inputs to later layers, making it difficult to train later layers.\n",
    "\n",
    "[Batch Normalization](https://arxiv.org/abs/1502.03167) addresses this problem by normalizing distributions of inputs to layers within mini-batches. It typically allows to train networks faster and/or with higher learning rates, lessens the importance\n",
    "of initialization and might eliminate the need for Dropout.\n",
    "\n",
    "Implement Batch Normalization and compare with regular training of MNIST models.\n",
    "\n",
    "Remember to use the batch statistics during model training and to use an average of training batch statistics during model evaluation. For details please consult the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 6: Norm Constraints [1p bonus]\n",
    "\n",
    "Implement norm constraints, i.e. instead of weight decay, that tries to set \n",
    "all weights to small values, apply a limit on the total\n",
    "norm of connections incoming to a neuron. In our case, this\n",
    "corresponds to clipping the norm of *rows* of weight\n",
    "matrices. An easy way of implementing it is to make a gradient\n",
    "step, then look at the norm of rows and scale down those that are\n",
    "over the threshold (this technique is called \"projected gradient descent\").\n",
    "\n",
    "Please consult the Dropout paper (http://arxiv.org/pdf/1207.0580.pdf) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6: Polyak Averaging [1p bonus]\n",
    "\n",
    "Implement Polyak averaging. For each parameter $\\theta$\n",
    "keep a separate, exponentially decayed average of the past values\n",
    "$$\n",
    "\\bar{\\theta}_n = \\alpha_p\\bar{\\theta}_{n-1} + (1-\\alpha_p)\\theta_n.\n",
    "$$\n",
    "Use that average when evaluating the model on the test set.\n",
    "Validate the approach by training a model on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7: Convolutional Network [2p bonus]\n",
    "\n",
    "Use convolutional and max-pooling layers (`torch.nn.functional.conv2d`, `torch.nn.functional.max_pool2d`) and (without dropout) get a test error rate below 1.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8: Hyperparameter tuner [1p bonus]\n",
    "\n",
    "Implement a hyper-parameter tuner able to optimize the learing rate schedule, number of neurons and similar hyperparameters. For start, use random search (please see http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf and especially Fig 1. for intuitions on why random search is better than grid search). It may be a good idea to use a fixed maximum number of epochs (or training time) for each optimization trial to prevent selecting hyperparameters that yield slowly converging solutions. A good result will be a set of hyperparameters that reach on MNIST solutions with test errors less than $1.3\\%$ in no more than 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
