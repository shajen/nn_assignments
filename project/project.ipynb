{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.ndimage\n",
    "\n",
    "import PIL\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"PIL\").setLevel(logging.INFO)\n",
    "\n",
    "import common.plotting\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import tensorflow\n",
    "\n",
    "import os\n",
    "import ot\n",
    "import itertools\n",
    "import datetime\n",
    "import sys\n",
    "from random import randint\n",
    "from pyriemann.utils.distance import *\n",
    "\n",
    "os.environ['TORCH_MODEL_ZOO'] =  os.environ['PYTORCH_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We strongly recommend training using CUDA on lab computers\n",
    "CUDA = True\n",
    "\n",
    "def to_np(x):\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "    return x.cpu().numpy()\n",
    "\n",
    "def to_variable(x, **kwargs):\n",
    "    x = torch.from_numpy(x)\n",
    "    if CUDA:\n",
    "        x = x.cuda()\n",
    "    return Variable(x, **kwargs)\n",
    "\n",
    "def log(text):\n",
    "    print('%s | %s' % (datetime.datetime.now(), text))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view((x.size(0), ) + self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ot\n",
    "\n",
    "def ground_matrix(n):\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            x.append([i, j])\n",
    "    x = np.array(x)\n",
    "    M = ot.dist(x, x, 'sqeuclidean')\n",
    "    return M\n",
    "\n",
    "def sqeuclidean_wasserstein_distance(x, y):\n",
    "    x = to_np(x)\n",
    "    y = to_np(y)\n",
    "    M = ground_matrix(x.shape[1])\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    return torch.Tensor([ot.emd2(x[i], y[i], M) for i in range(0, x.shape[0])])\n",
    "\n",
    "def kl(x, y):\n",
    "    x = torch.squeeze(x, 1)\n",
    "    y = torch.squeeze(y, 1)\n",
    "    return torch.nn.functional.kl_div(x, y, size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log('start')\n",
    "samples = 1000000\n",
    "\n",
    "try:\n",
    "    log('read images, labels, distances from files')\n",
    "    images = torch.load('/tmp/data/%d/images.pt' % samples)\n",
    "    labels = torch.load('/tmp/data/%d/labels.pt' % samples)\n",
    "    distances = torch.load('/tmp/data/%d/distances.pt' % samples)\n",
    "except Exception as e:\n",
    "    log('error, calucalting new data')\n",
    "    data_path = os.environ.get('PYTORCH_DATA_PATH', '../data')\n",
    "\n",
    "    dataset = torchvision.datasets.MNIST(data_path, train=True, download=True)\n",
    "    imagesList = dataset.train_data\n",
    "    imagesList = imagesList.squeeze(1).float()\n",
    "    imagesList = imagesList.div(imagesList.sum(1).sum(1).unsqueeze(1).unsqueeze(1))\n",
    "    labelsList = dataset.train_labels\n",
    "\n",
    "    indexes = set()\n",
    "    while len(indexes) < samples:\n",
    "        indexes.add((randint(0, imagesList.size(0)-1), randint(0, imagesList.size(0)-1)))\n",
    "    indexes = [j for i in list(indexes) for j in i]\n",
    "\n",
    "    images = torch.index_select(imagesList, 0, torch.LongTensor(indexes))\n",
    "    labels = torch.index_select(labelsList, 0, torch.LongTensor(indexes))\n",
    "    images = images.view(-1, 2, images.size(1), images.size(2))\n",
    "    labels = labels.view(-1, 2)\n",
    "    distances = sqeuclidean_wasserstein_distance(images[:, 0], images[:, 1])\n",
    "    \n",
    "    if not os.path.exists('/tmp/data'):\n",
    "        os.mkdir('/tmp/data')\n",
    "    if not os.path.exists('/tmp/data/%d' % samples):\n",
    "        os.mkdir('/tmp/data/%d' % samples)\n",
    "    \n",
    "    torch.save(images, '/tmp/data/%d/images.pt' % samples)\n",
    "    torch.save(labels, '/tmp/data/%d/labels.pt' % samples)\n",
    "    torch.save(distances, '/tmp/data/%d/distances.pt' % samples)    \n",
    "    \n",
    "log('%d samples count' % images.size(0))\n",
    "log('distances sum: %.2f' % distances.sum())\n",
    "log('distances min: %.2f' % distances.min())\n",
    "log('distances max: %.2f' % distances.max())\n",
    "\n",
    "n_train = int(images.size(0) * 0.7)\n",
    "n_valid = int(images.size(0) * 0.9)\n",
    "train_images = images[:n_train]\n",
    "train_labels = labels[:n_train]\n",
    "train_distances = distances[:n_train]\n",
    "\n",
    "valid_images = images[n_train:n_valid]\n",
    "valid_labels = labels[n_train:n_valid]\n",
    "valid_distances = distances[n_train:n_valid]\n",
    "\n",
    "test_images = images[n_valid:]\n",
    "test_labels = labels[n_valid:]\n",
    "test_distances = distances[n_valid:]\n",
    "\n",
    "log('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(model, allX, allY):\n",
    "    batch_size = 200\n",
    "    i = 0\n",
    "    mse = 0.0\n",
    "    while i < allX.size(0):\n",
    "        x = Variable(allX[i:i+batch_size])\n",
    "        y = Variable(allY[i:i+batch_size])\n",
    "        if CUDA:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        outputs = model(x)\n",
    "        diff = (outputs - y).data\n",
    "        mse = mse + torch.sum(diff ** 2)\n",
    "        i = i + batch_size\n",
    "    return mse / allX.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log('start')\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1, 20, kernel_size=3, padding=0),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(20, 10, kernel_size=3, padding=0),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(10, 5, kernel_size=5, padding=0),\n",
    "                nn.ReLU()),\n",
    "            Reshape(-1),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2000, 100),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(100, 50),\n",
    "                nn.ReLU())\n",
    "        )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(50, 100),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(100, 5 * 28 * 28),\n",
    "#                 nn.ReLU()),\n",
    "#             Reshape(5, 28, 28),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(5, 1, kernel_size=1, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(10, 20, kernel_size=3, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(20, 1, kernel_size=3, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Softmax2d()\n",
    "#         )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data1 = data[:, 0].unsqueeze(1)\n",
    "        encoder1 = self.encoder(data1)\n",
    "        #decoder1 = self.decoder(encoder1)\n",
    "        kl_factor1 = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "        \n",
    "        data2 = data[:, 1].unsqueeze(1)\n",
    "        encoder2 = self.encoder(data2)\n",
    "        #decoder2 = self.decoder(encoder2)\n",
    "        kl_factor2 = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "            \n",
    "        encoder_difference = encoder1 - encoder2\n",
    "        encoder_factor = torch.torch.matmul(encoder_difference, encoder_difference.transpose(0, 1)).diag()\n",
    "        \n",
    "        wasserstein_factor = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "        \n",
    "        return encoder_factor\n",
    "#         return kl_factor1 + (encoder_factor - wasserstein_factor).pow(2) + kl_factor2\n",
    "      \n",
    "num_epochs = 1\n",
    "patience_expansion = 1.5\n",
    "best_value_error = 1000000.0\n",
    "learning_rate = 0.0001\n",
    "batch_size = 2000\n",
    "epoch = 0\n",
    "best_params = None\n",
    "\n",
    "cnn = CNN()\n",
    "if CUDA:\n",
    "    cnn.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "try:\n",
    "    while epoch < num_epochs:\n",
    "        epoch += 1\n",
    "        i = 0\n",
    "        while i < train_images.size(0):\n",
    "            optimizer.zero_grad()\n",
    "            x = Variable(train_images[i:i+batch_size])\n",
    "            y = Variable(train_distances[i:i+batch_size])\n",
    "            if CUDA:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            outputs = cnn(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i = i + batch_size\n",
    "\n",
    "        value_error = compute_error_rate(cnn, valid_images, valid_distances)\n",
    "        if (value_error < best_value_error):\n",
    "            best_value_error = value_error\n",
    "            num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
    "            best_params = [p.clone().cpu() for p in cnn.parameters()]\n",
    "\n",
    "        log('epoch [%d/%d]' % (epoch, num_epochs))        \n",
    "        log('validation set errors: %.2f' % value_error)\n",
    "        print('')\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "    \n",
    "if best_params is not None:\n",
    "    cnn.parameters = best_params\n",
    "    \n",
    "# Test the Model\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "log('test set errors: %.2f' % compute_error_rate(cnn, test_images, test_distances))\n",
    "\n",
    "# Save the Trained Model\n",
    "torch.save(cnn.state_dict(), 'cnn.pkl')\n",
    "\n",
    "log('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
