{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.ndimage\n",
    "\n",
    "import PIL\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"PIL\").setLevel(logging.INFO)\n",
    "\n",
    "import common.plotting\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import tensorflow\n",
    "\n",
    "import os\n",
    "import ot\n",
    "import itertools\n",
    "import datetime\n",
    "import sys\n",
    "from random import randint\n",
    "from pyriemann.utils.distance import *\n",
    "\n",
    "os.environ['TORCH_MODEL_ZOO'] =  os.environ['PYTORCH_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We strongly recommend training using CUDA on lab computers\n",
    "CUDA = True\n",
    "\n",
    "def to_np(x):\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "    return x.cpu().numpy()\n",
    "\n",
    "def to_variable(x, **kwargs):\n",
    "    x = torch.from_numpy(x)\n",
    "    if CUDA:\n",
    "        x = x.cuda()\n",
    "    return Variable(x, **kwargs)\n",
    "\n",
    "def log(text):\n",
    "    print('%s | %s' % (datetime.datetime.now(), text))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view((x.size(0), ) + self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ot\n",
    "\n",
    "def ground_matrix(n):\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            x.append([i, j])\n",
    "    x = np.array(x)\n",
    "    M = ot.dist(x, x, 'sqeuclidean')\n",
    "    return M\n",
    "\n",
    "def sqeuclidean_wasserstein_distance(x, y):\n",
    "    x = to_np(x)\n",
    "    y = to_np(y)\n",
    "    M = ground_matrix(x.shape[1])\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    return torch.Tensor([ot.emd2(x[i], y[i], M) for i in range(0, x.shape[0])])\n",
    "\n",
    "def kl(x, y):\n",
    "    x = torch.squeeze(x, 1)\n",
    "    y = torch.squeeze(y, 1)\n",
    "    return torch.nn.functional.kl_div(x, y, size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log('start')\n",
    "data_path = os.environ.get('PYTORCH_DATA_PATH', '../data')\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(data_path, train=True, download=True)\n",
    "imagesList = dataset.train_data\n",
    "imagesList = imagesList.squeeze(1).float()\n",
    "imagesList = imagesList.div(imagesList.sum(1).sum(1).unsqueeze(1).unsqueeze(1))\n",
    "labelsList = dataset.train_labels\n",
    "\n",
    "indexes = set()\n",
    "while len(indexes) < 1000000:\n",
    "    indexes.add((randint(0, imagesList.size(0)-1), randint(0, imagesList.size(0)-1)))\n",
    "indexes = [j for i in list(indexes) for j in i]\n",
    "log('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log('start')\n",
    "\n",
    "images = torch.index_select(imagesList, 0, torch.LongTensor(indexes))\n",
    "labels = torch.index_select(labelsList, 0, torch.LongTensor(indexes))\n",
    "images = images.view(-1, 2, images.size(1), images.size(2))\n",
    "labels = labels.view(-1, 2)\n",
    "distances = sqeuclidean_wasserstein_distance(images[:, 0], images[:, 1])\n",
    "print(distances.sum())\n",
    "print(distances.min())\n",
    "print(distances.max())\n",
    "\n",
    "n_train = int(images.size(0) * 0.7)\n",
    "n_valid = int(images.size(0) * 0.9)\n",
    "train_images = images[:n_train]\n",
    "train_labels = labels[:n_train]\n",
    "train_distances = distances[:n_train]\n",
    "\n",
    "valid_images = images[n_train:n_valid]\n",
    "valid_labels = labels[n_train:n_valid]\n",
    "valid_distances = distances[n_train:n_valid]\n",
    "\n",
    "test_images = images[n_valid:]\n",
    "test_labels = labels[n_valid:]\n",
    "test_distances = distances[n_valid:]\n",
    "\n",
    "log('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(model, x, y):\n",
    "    batch_size = 100\n",
    "    i = 0\n",
    "    mse = 0.0\n",
    "    while i < x.size(0):\n",
    "        outputs = model.forward(x[i:i+batch_size])\n",
    "        diff = (outputs - y[i:i+batch_size]).data\n",
    "        mse = mse + torch.sum(diff ** 2)\n",
    "        i = i + batch_size\n",
    "    #return 'sum = %.2f, median = %.2f, mse = %.2f' % (diff.sum(), diff.median(), torch.sum(diff ** 2))\n",
    "    return 'mse = %.2f' % (mse / x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log('start')\n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1, 20, kernel_size=3, padding=0),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(20, 10, kernel_size=3, padding=0),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(10, 5, kernel_size=5, padding=0),\n",
    "                nn.ReLU()),\n",
    "            Reshape(-1),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2000, 100),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(100, 50),\n",
    "                nn.ReLU())\n",
    "        )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(50, 100),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(100, 5 * 28 * 28),\n",
    "#                 nn.ReLU()),\n",
    "#             Reshape(5, 28, 28),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(5, 1, kernel_size=1, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(10, 20, kernel_size=3, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(20, 1, kernel_size=3, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Softmax2d()\n",
    "#         )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data1 = data[:, 0].unsqueeze(1)\n",
    "        encoder1 = self.encoder(data1)\n",
    "        #decoder1 = self.decoder(encoder1)\n",
    "        kl_factor1 = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "        \n",
    "        data2 = data[:, 1].unsqueeze(1)\n",
    "        encoder2 = self.encoder(data2)\n",
    "        #decoder2 = self.decoder(encoder2)\n",
    "        kl_factor2 = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "            \n",
    "        encoder_difference = encoder1 - encoder2\n",
    "        encoder_factor = torch.torch.matmul(encoder_difference, encoder_difference.transpose(0, 1)).diag()\n",
    "        \n",
    "        wasserstein_factor = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "        \n",
    "        return encoder_factor#.sum(1)\n",
    "#         return kl_factor1 + (encoder_factor - wasserstein_factor).pow(2) + kl_factor2\n",
    "        \n",
    "cnn = CNN()\n",
    "if CUDA:\n",
    "    cnn.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "train_images_variable = Variable(train_images)\n",
    "train_labels_variable = Variable(train_labels)\n",
    "train_distances_variable = Variable(train_distances)\n",
    "\n",
    "valid_images_variable = Variable(valid_images)\n",
    "valid_labels_variable = Variable(valid_labels)\n",
    "valid_distances_variable = Variable(valid_distances)\n",
    "\n",
    "test_images_variable = Variable(test_images)\n",
    "test_labels_variable = Variable(test_labels)\n",
    "test_distances_variable = Variable(test_distances)\n",
    "\n",
    "if CUDA:\n",
    "    train_images_variable = train_images_variable.cuda()\n",
    "    train_labels_variable = train_labels_variable.cuda()\n",
    "    train_distances_variable = train_distances_variable.cuda()\n",
    "\n",
    "    valid_images_variable = valid_images_variable.cuda()\n",
    "    valid_labels_variable = valid_labels_variable.cuda()\n",
    "    valid_distances_variable = valid_distances_variable.cuda()\n",
    "\n",
    "    test_images_variable = test_images_variable.cuda()\n",
    "    test_labels_variable = test_labels_variable.cuda()\n",
    "    test_distances_variable = test_distances_variable.cuda()\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    i = 0\n",
    "    while i < train_images.size(0):\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(train_images_variable[i:i+batch_size])\n",
    "        loss = criterion(outputs, train_distances_variable[i:i+batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         log((train_distances_variable - outputs).data[1])\n",
    "#         log('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data[0]))\n",
    "        i = i + batch_size\n",
    "    log('epoch [%d/%d]' % (epoch + 1, num_epochs))\n",
    "    log('train set errors:      ' + compute_error_rate(cnn, train_images_variable, train_distances_variable))\n",
    "    log('validation set errors: ' + compute_error_rate(cnn, valid_images_variable, valid_distances_variable))\n",
    "    print('')\n",
    "        \n",
    "# Test the Model\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "log('test set errors:       ' + compute_error_rate(cnn, test_images_variable, test_distances_variable))\n",
    "\n",
    "# Save the Trained Model\n",
    "torch.save(cnn.state_dict(), 'cnn.pkl')\n",
    "\n",
    "log('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
