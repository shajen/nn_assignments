{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.ndimage\n",
    "\n",
    "import PIL\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"PIL\").setLevel(logging.INFO)\n",
    "\n",
    "import common.plotting\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import tensorflow\n",
    "\n",
    "import os\n",
    "import ot\n",
    "import itertools\n",
    "import datetime\n",
    "import sys\n",
    "from random import randint\n",
    "from pyriemann.utils.distance import *\n",
    "\n",
    "os.environ['TORCH_MODEL_ZOO'] =  os.environ['PYTORCH_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We strongly recommend training using CUDA on lab computers\n",
    "CUDA = True\n",
    "\n",
    "LOG_FILE = 'stdout.txt'\n",
    "\n",
    "if os.path.exists(LOG_FILE):\n",
    "    os.remove(LOG_FILE)\n",
    "\n",
    "def to_np(x):\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "    return x.cpu().numpy()\n",
    "\n",
    "def to_variable(x, **kwargs):\n",
    "    x = torch.from_numpy(x)\n",
    "    if CUDA:\n",
    "        x = x.cuda()\n",
    "    return Variable(x, **kwargs)\n",
    "\n",
    "def log(text):\n",
    "    text = '%s | %s' % (datetime.datetime.now(), text)\n",
    "    with open(LOG_FILE, 'a') as file:\n",
    "        file.write(text + '\\n')\n",
    "        file.flush()\n",
    "    print(text)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view((x.size(0), ) + self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ot\n",
    "\n",
    "def ground_matrix(n):\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            x.append([i, j])\n",
    "    x = np.array(x)\n",
    "    M = ot.dist(x, x, 'sqeuclidean')\n",
    "    return M\n",
    "\n",
    "def sqeuclidean_wasserstein_distance(x, y):\n",
    "    x = to_np(x)\n",
    "    y = to_np(y)\n",
    "    M = ground_matrix(x.shape[1])\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    return torch.Tensor([ot.emd2(x[i], y[i], M) for i in range(0, x.shape[0])])\n",
    "\n",
    "def kl(x, y):\n",
    "    x = torch.squeeze(x, 1)\n",
    "    y = torch.squeeze(y, 1)\n",
    "    return torch.nn.functional.kl_div(x, y, size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-09 23:34:36.173482 | start\n",
      "2018-01-09 23:34:36.189326 | read images, labels, distances from files\n",
      "2018-01-09 23:34:36.364430 | 100000 samples count\n",
      "2018-01-09 23:34:36.379456 | distances sum: 1139728.84\n",
      "2018-01-09 23:34:36.390840 | distances min: 0.00\n",
      "2018-01-09 23:34:36.402711 | distances max: 63.68\n",
      "2018-01-09 23:34:36.414516 | finish\n"
     ]
    }
   ],
   "source": [
    "log('start')\n",
    "samples = 100000\n",
    "\n",
    "patch='/pio/scratch/1/i233123/data_mnist'\n",
    "try:\n",
    "    log('read images, labels, distances from files')\n",
    "    images = torch.load('%s/%d/images.pt' % (patch, samples))\n",
    "    labels = torch.load('%s/%d/labels.pt' % (patch, samples))\n",
    "    distances = torch.load('%s/%d/distances.pt' % (patch, samples))\n",
    "except Exception as e:\n",
    "    log('error, calucalting new data')\n",
    "    data_path = os.environ.get('PYTORCH_DATA_PATH', '../data')\n",
    "\n",
    "    dataset = torchvision.datasets.MNIST(data_path, train=True, download=True)\n",
    "    imagesList = dataset.train_data\n",
    "    imagesList = imagesList.squeeze(1).double()\n",
    "    imagesList = imagesList.div(imagesList.sum(1).sum(1).unsqueeze(1).unsqueeze(1))\n",
    "    labelsList = dataset.train_labels\n",
    "\n",
    "    indexes = set()\n",
    "    while len(indexes) < samples:\n",
    "        indexes.add((randint(0, imagesList.size(0)-1), randint(0, imagesList.size(0)-1)))\n",
    "    indexes = [j for i in list(indexes) for j in i]\n",
    "\n",
    "    images = torch.index_select(imagesList, 0, torch.LongTensor(indexes))\n",
    "    labels = torch.index_select(labelsList, 0, torch.LongTensor(indexes))\n",
    "    images = images.view(-1, 2, images.size(1), images.size(2))\n",
    "    labels = labels.view(-1, 2)\n",
    "    distances = sqeuclidean_wasserstein_distance(images[:, 0], images[:, 1])\n",
    "    \n",
    "    images = images.float()\n",
    "    distances = distances.float()\n",
    "    \n",
    "    if not os.path.exists(patch):\n",
    "        os.mkdir(patch)\n",
    "    if not os.path.exists('%s/%d' % (patch, samples)):\n",
    "        os.mkdir('%s/%d' % (patch, samples))\n",
    "        \n",
    "    torch.save(images, '%s/%d/images.pt' % (patch, samples))\n",
    "    torch.save(labels, '%s/%d/labels.pt' % (patch, samples))\n",
    "    torch.save(distances, '%s/%d/distances.pt' % (patch, samples))\n",
    "    \n",
    "log('%d samples count' % images.size(0))\n",
    "log('distances sum: %.2f' % distances.sum())\n",
    "log('distances min: %.2f' % distances.min())\n",
    "log('distances max: %.2f' % distances.max())\n",
    "\n",
    "n_train = int(images.size(0) * 0.7)\n",
    "n_valid = int(images.size(0) * 0.9)\n",
    "train_images = images[:n_train]\n",
    "train_labels = labels[:n_train]\n",
    "train_distances = distances[:n_train]\n",
    "\n",
    "valid_images = images[n_train:n_valid]\n",
    "valid_labels = labels[n_train:n_valid]\n",
    "valid_distances = distances[n_train:n_valid]\n",
    "\n",
    "test_images = images[n_valid:]\n",
    "test_labels = labels[n_valid:]\n",
    "test_distances = distances[n_valid:]\n",
    "\n",
    "log('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distances_matrix_sum = np.zeros((10, 10))\n",
    "distances_matrix_count = np.zeros((10, 10))\n",
    "\n",
    "for i in range(samples):\n",
    "    l1 = max(labels[i])\n",
    "    l2 = min(labels[i])\n",
    "    distances_matrix_sum[l1][l2] += distances[i]\n",
    "    distances_matrix_count[l1][l2] += 1\n",
    "    \n",
    "# np.set_printoptions(precision=2)\n",
    "# print(distances_matrix_sum)\n",
    "# print(distances_matrix_count)\n",
    "# print(distances_matrix_sum / distances_matrix_count)\n",
    "\n",
    "# from common.plotting import plot_mat\n",
    "# for i in range(10):\n",
    "#     d = sqeuclidean_wasserstein_distance(images[i][0].unsqueeze(0), images[i][1].unsqueeze(0))[0]\n",
    "#     lol = to_np(images[i])\n",
    "#     lol = np.array([lol[0], lol[1]])\n",
    "#     lol = np.expand_dims(lol, axis=1)\n",
    "#     plot_mat(lol, cmap='gray')\n",
    "#     plt.title(\"Distance: %.2f\" % d)\n",
    "#     show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(model, allX, allY):\n",
    "    batch_size = 200\n",
    "    i = 0\n",
    "    mse = 0.0\n",
    "    while i < allX.size(0):\n",
    "        x = Variable(allX[i:i+batch_size])\n",
    "        y = Variable(allY[i:i+batch_size])\n",
    "        if CUDA:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        outputs = model(x)\n",
    "        diff = (outputs - y).data\n",
    "        mse = mse + torch.sum(diff ** 2)\n",
    "        i = i + batch_size\n",
    "    return mse / allX.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-09 23:34:38.319422 | start\n",
      "2018-01-09 23:34:46.560819 | epoch [1/2]\n",
      "2018-01-09 23:34:46.573431 | validation set errors: 54.31\n",
      "\n",
      "2018-01-09 23:34:52.559497 | epoch [2/4]\n",
      "2018-01-09 23:34:52.571184 | validation set errors: 20.75\n",
      "\n",
      "2018-01-09 23:34:58.468679 | epoch [3/5]\n",
      "2018-01-09 23:34:58.480284 | validation set errors: 18.31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log('start')\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1, 20, kernel_size=3, padding=0),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(20, 10, kernel_size=3, padding=0),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(10, 5, kernel_size=5, padding=0),\n",
    "                nn.ReLU()),\n",
    "            Reshape(-1),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2000, 100),\n",
    "                nn.ReLU()),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(100, 50),\n",
    "                nn.ReLU())\n",
    "        )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(50, 100),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(100, 5 * 28 * 28),\n",
    "#                 nn.ReLU()),\n",
    "#             Reshape(5, 28, 28),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(5, 1, kernel_size=1, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(10, 20, kernel_size=3, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(20, 1, kernel_size=3, padding=0),\n",
    "#                 nn.ReLU()),\n",
    "#             nn.Softmax2d()\n",
    "#         )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data1 = data[:, 0].unsqueeze(1)\n",
    "        encoder1 = self.encoder(data1)\n",
    "        #decoder1 = self.decoder(encoder1)\n",
    "        kl_factor1 = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "        \n",
    "        data2 = data[:, 1].unsqueeze(1)\n",
    "        encoder2 = self.encoder(data2)\n",
    "        #decoder2 = self.decoder(encoder2)\n",
    "        kl_factor2 = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "            \n",
    "        encoder_difference = encoder1 - encoder2\n",
    "        encoder_factor = torch.torch.matmul(encoder_difference, encoder_difference.transpose(0, 1)).diag()\n",
    "        \n",
    "        wasserstein_factor = Variable(torch.zeros(data1.size(0)).cuda())\n",
    "        \n",
    "        return encoder_factor\n",
    "#         return kl_factor1 + (encoder_factor - wasserstein_factor).pow(2) + kl_factor2\n",
    "      \n",
    "num_epochs = 1\n",
    "patience_expansion = 1.5\n",
    "best_value_error = 1000000.0\n",
    "learning_rate = 0.0001\n",
    "batch_size = 100\n",
    "epoch = 0\n",
    "best_params = None\n",
    "\n",
    "cnn = CNN()\n",
    "if CUDA:\n",
    "    cnn.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "try:\n",
    "    while epoch < num_epochs:\n",
    "        epoch += 1\n",
    "        i = 0\n",
    "        while i < train_images.size(0):\n",
    "            optimizer.zero_grad()\n",
    "            x = Variable(train_images[i:i+batch_size])\n",
    "            y = Variable(train_distances[i:i+batch_size])\n",
    "            if CUDA:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            outputs = cnn(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i = i + batch_size\n",
    "\n",
    "        value_error = compute_error_rate(cnn, valid_images, valid_distances)\n",
    "        if (value_error < best_value_error):\n",
    "            best_value_error = value_error\n",
    "            num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
    "            best_params = [p.clone().cpu() for p in cnn.parameters()]\n",
    "\n",
    "        log('epoch [%d/%d]' % (epoch, num_epochs))        \n",
    "        log('validation set errors: %.2f' % value_error)\n",
    "        print('')\n",
    "        \n",
    "        torch.save(cnn.state_dict(), 'cnn.pkl')\n",
    "        torch.save(optimizer.state_dict(), 'optimizer.pkl')\n",
    "        with open('config.txt', 'w') as file:\n",
    "            file.write(\"samples            %d\\n\" % (samples))\n",
    "            file.write(\"num_epochs         %d\\n\" % (num_epochs))\n",
    "            file.write(\"epoch              %d\\n\" % (epoch))\n",
    "            file.write(\"batch_size         %d\\n\" % (batch_size))\n",
    "            file.write(\"patience_expansion %.2f\\n\" % (patience_expansion))\n",
    "            file.write(\"best_value_error   %.2f\\n\" % (best_value_error))\n",
    "            file.write(\"learning_rate      %.2f\\n\" % (learning_rate))\n",
    "            file.flush()\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "    \n",
    "if best_params is not None:\n",
    "    cnn.parameters = best_params\n",
    "    \n",
    "# Test the Model\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "log('test set errors: %.2f' % compute_error_rate(cnn, test_images, test_distances))\n",
    "\n",
    "torch.save(cnn.state_dict(), 'cnn.pkl')\n",
    "torch.save(optimizer.state_dict(), 'optimizer.pkl')\n",
    "        \n",
    "log('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
